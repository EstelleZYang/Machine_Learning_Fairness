{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83ad06c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from cvxpy import *\n",
    "from dtool import *\n",
    "from matplotlib import gridspec\n",
    "from matplotlib.patches import Rectangle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5f50759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install cvxpy\n",
    "# !pip3 install dtool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08c4de04",
   "metadata": {},
   "outputs": [],
   "source": [
    "path =r'../data/experiment_data2/' # use your path\n",
    "train_0 = pd.read_csv(path + \"train_0.csv\",index_col=None, header=0, usecols=range(1,6))\n",
    "train_1 = pd.read_csv(path + \"train_1.csv\",index_col=None, header=0, usecols=range(1,6))\n",
    "train_2 = pd.read_csv(path + \"train_2.csv\",index_col=None, header=0, usecols=range(1,6))\n",
    "train_3 = pd.read_csv(path + \"train_3.csv\",index_col=None, header=0, usecols=range(1,6))\n",
    "train_4 = pd.read_csv(path + \"train_4.csv\",index_col=None, header=0, usecols=range(1,6))\n",
    "test_0 = pd.read_csv(path + \"test_0.csv\",index_col=None, header=0, usecols=range(1,6))\n",
    "test_1 = pd.read_csv(path + \"test_1.csv\",index_col=None, header=0, usecols=range(1,6))\n",
    "test_2 = pd.read_csv(path + \"test_2.csv\",index_col=None, header=0, usecols=range(1,6))\n",
    "test_3 = pd.read_csv(path + \"test_3.csv\",index_col=None, header=0, usecols=range(1,6))\n",
    "test_4 = pd.read_csv(path + \"test_4.csv\",index_col=None, header=0, usecols=range(1,6))\n",
    "train_new_0 = pd.read_csv(path + \"train_new_0.csv\",index_col=None, header=0, usecols=range(1,6))\n",
    "train_new_1 = pd.read_csv(path + \"train_new_1.csv\",index_col=None, header=0, usecols=range(1,6))\n",
    "train_new_2 = pd.read_csv(path + \"train_new_2.csv\",index_col=None, header=0, usecols=range(1,6))\n",
    "train_new_3 = pd.read_csv(path + \"train_new_3.csv\",index_col=None, header=0, usecols=range(1,6))\n",
    "train_new_4 = pd.read_csv(path + \"train_new_4.csv\",index_col=None, header=0, usecols=range(1,6))\n",
    "test_new_0 = pd.read_csv(path + \"test_new_0.csv\",index_col=None, header=0, usecols=range(1,6))\n",
    "test_new_1 = pd.read_csv(path + \"test_new_1.csv\",index_col=None, header=0, usecols=range(1,6))\n",
    "test_new_2 = pd.read_csv(path + \"test_new_2.csv\",index_col=None, header=0, usecols=range(1,6))\n",
    "test_new_3 = pd.read_csv(path + \"test_new_3.csv\",index_col=None, header=0, usecols=range(1,6))\n",
    "test_new_4 = pd.read_csv(path + \"test_new_4.csv\",index_col=None, header=0, usecols=range(1,6))\n",
    "features = ['race','age_cat','c_charge_degree','priors_count','is_recid']\n",
    "D_features = ['race']\n",
    "Y_features = ['is_recid']\n",
    "X_features = ['age_cat', 'c_charge_degree','priors_count']\n",
    "\n",
    "TrainList=[train_0,train_1,train_2,train_3,train_4]\n",
    "TestList=[test_0,test_1,test_2,test_3,test_4]\n",
    "TrainNewList=[train_new_0,train_new_1,train_new_2,train_new_3,train_new_4]\n",
    "TestNewList=[test_new_0,test_new_1,test_new_2,test_new_3,test_new_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f15974a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, auc, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9dccf79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RunLRClassifier(TrainList,TestList,TrainNewList,TestNewList,D_features,X_features,Y_features):\n",
    "    LRModelsAUC=[]\n",
    "    LRTestPreds=[]\n",
    "    for i in range(0,len(TrainNewList)):\n",
    "        dft = pd.get_dummies(TrainNewList[i][D_features+X_features])\n",
    "        lr=LogisticRegression()\n",
    "        lr.fit(dft,TrainNewList[i][Y_features])\n",
    "        dft = pd.get_dummies(TestNewList[i][D_features+X_features])\n",
    "        proba=lr.predict_proba(dft)\n",
    "        ytrue=TestList[i][Y_features]\n",
    "        testauc=roc_auc_score(ytrue, proba[:, 1])\n",
    "        LRModelsAUC.append(testauc)\n",
    "        dft=TestList[i][D_features+X_features+Y_features]\n",
    "        dft['pred']=proba[:,1]\n",
    "        LRTestPreds.append(dft)\n",
    "    return LRModelsAUC,LRTestPreds\n",
    "\n",
    "def RunLRWithoutDClassifier(TrainList,TestList,D_features,X_features,Y_features):\n",
    "    LRModelsAUC=[]\n",
    "    LRTestPreds=[]\n",
    "    for i in range(0,len(TrainList)): \n",
    "        dft = pd.get_dummies(TrainList[i][X_features])\n",
    "        lr=LogisticRegression()\n",
    "        lr.fit(dft,TrainList[i][Y_features])\n",
    "        dft = pd.get_dummies(TestList[i][X_features])\n",
    "        proba=lr.predict_proba(dft)\n",
    "        ytrue=TestList[i][Y_features]\n",
    "        testauc=roc_auc_score(ytrue, proba[:, 1])\n",
    "        LRModelsAUC.append(testauc)\n",
    "        dft=TestList[i][D_features+X_features+Y_features]\n",
    "        dft['pred']=proba[:,1]\n",
    "        LRTestPreds.append(dft)\n",
    "    return LRModelsAUC,LRTestPreds\n",
    "\n",
    "def RunPlainLRClassifier(TrainList,TestList,D_features,X_features,Y_features):\n",
    "    LRModelsAUC=[]\n",
    "    LRTestPreds=[]\n",
    "    for i in range(0,len(TrainList)): \n",
    "        dft = pd.get_dummies(TrainList[i][D_features+X_features])\n",
    "        lr=LogisticRegression()\n",
    "        lr.fit(dft,TrainList[i][Y_features])\n",
    "        dft = pd.get_dummies(TestList[i][D_features+X_features])\n",
    "        proba=lr.predict_proba(dft)\n",
    "        ytrue=TestList[i][Y_features]\n",
    "        testauc=roc_auc_score(ytrue, proba[:, 1])\n",
    "        LRModelsAUC.append(testauc)\n",
    "        dft=TestList[i][D_features+X_features+Y_features]\n",
    "        dft['pred']=proba[:,1]\n",
    "        LRTestPreds.append(dft)\n",
    "    return LRModelsAUC,LRTestPreds\n",
    "\n",
    "def RunRFClassifier(TrainList,TestList,TrainNewList,TestNewList,D_features,X_features,Y_features):\n",
    "    RFModelsAUC=[]\n",
    "    RFTestPreds=[]\n",
    "    for i in range(0,len(TrainNewList)):\n",
    "        dft = pd.get_dummies(TrainNewList[i][D_features+X_features])\n",
    "        rf=RandomForestClassifier()\n",
    "        rf.fit(dft,TrainNewList[i][Y_features])\n",
    "        dft = pd.get_dummies(TestNewList[i][D_features+X_features])\n",
    "        proba=rf.predict_proba(dft)\n",
    "        ytrue=TestList[i][Y_features]\n",
    "        testauc=roc_auc_score(ytrue, proba[:, 1])\n",
    "        RFModelsAUC.append(testauc)\n",
    "        dft=TestList[i][D_features+X_features+Y_features]\n",
    "        dft['pred']=proba[:,1]\n",
    "        RFTestPreds.append(dft)\n",
    "    return RFModelsAUC,RFTestPreds\n",
    "\n",
    "def RunRFWithoutDClassifier(TrainList,TestList,D_features,X_features,Y_features):\n",
    "    RFModelsAUC=[]\n",
    "    RFTestPreds=[]\n",
    "    for i in range(0,len(TrainList)): \n",
    "        dft = pd.get_dummies(TrainList[i][X_features])\n",
    "        rf=RandomForestClassifier()\n",
    "        rf.fit(dft,TrainList[i][Y_features])\n",
    "        dft = pd.get_dummies(TestList[i][X_features])\n",
    "        proba=rf.predict_proba(dft)\n",
    "        ytrue=TestList[i][Y_features]\n",
    "        testauc=roc_auc_score(ytrue, proba[:, 1])\n",
    "        RFModelsAUC.append(testauc)\n",
    "        dft=TestList[i][D_features+X_features+Y_features]\n",
    "        dft['pred']=proba[:,1]\n",
    "        RFTestPreds.append(dft)\n",
    "    return RFModelsAUC,RFTestPreds\n",
    "\n",
    "def RunPlainRFClassifier(TrainList,TestList,D_features,X_features,Y_features):\n",
    "    RFModelsAUC=[]\n",
    "    RFTestPreds=[]\n",
    "    for i in range(0,len(TrainList)): \n",
    "        dft = pd.get_dummies(TrainList[i][D_features+X_features])\n",
    "        rf=RandomForestClassifier()\n",
    "        rf.fit(dft,TrainList[i][Y_features])\n",
    "        dft = pd.get_dummies(TestList[i][D_features+X_features])\n",
    "        proba=rf.predict_proba(dft)\n",
    "        ytrue=TestList[i][Y_features]\n",
    "        testauc=roc_auc_score(ytrue, proba[:, 1])\n",
    "        RFModelsAUC.append(testauc)\n",
    "        dft=TestList[i][D_features+X_features+Y_features]\n",
    "        dft['pred']=proba[:,1]\n",
    "        RFTestPreds.append(dft)\n",
    "    return RFModelsAUC,RFTestPreds\n",
    "\n",
    "\n",
    "def RunNBClassifier(TrainList,TestList,TrainNewList,TestNewList,D_features,X_features,Y_features):\n",
    "    NBModelsAUC=[]\n",
    "    NBTestPreds=[]\n",
    "    for i in range(0,len(TrainNewList)):\n",
    "        dft = pd.get_dummies(TrainNewList[i][D_features+X_features])\n",
    "        nb=MultinomialNB()\n",
    "        nb.fit(dft,TrainNewList[i][Y_features])\n",
    "        dft = pd.get_dummies(TestNewList[i][D_features+X_features])\n",
    "        proba=nb.predict_proba(dft)\n",
    "        ytrue=TestList[i][Y_features]\n",
    "        testauc=roc_auc_score(ytrue, proba[:, 1])\n",
    "        NBModelsAUC.append(testauc)\n",
    "        dft=TestList[i][D_features+X_features+Y_features]\n",
    "        dft['pred']=proba[:,1]\n",
    "        NBTestPreds.append(dft)\n",
    "    return NBModelsAUC,NBTestPreds\n",
    "\n",
    "def RunNBWithoutDClassifier(TrainList,TestList,D_features,X_features,Y_features):\n",
    "    NBModelsAUC=[]\n",
    "    NBTestPreds=[]\n",
    "    for i in range(0,len(TrainList)): \n",
    "        dft = pd.get_dummies(TrainList[i][X_features])\n",
    "        nb=MultinomialNB()\n",
    "        nb.fit(dft,TrainList[i][Y_features])\n",
    "        dft = pd.get_dummies(TestList[i][X_features])\n",
    "        proba=nb.predict_proba(dft)\n",
    "        ytrue=TestList[i][Y_features]\n",
    "        testauc=roc_auc_score(ytrue, proba[:, 1])\n",
    "        NBModelsAUC.append(testauc)\n",
    "        dft=TestList[i][D_features+X_features+Y_features]\n",
    "        dft['pred']=proba[:,1]\n",
    "        NBTestPreds.append(dft)\n",
    "    return NBModelsAUC,NBTestPreds\n",
    "\n",
    "def RunPlainNBClassifier(TrainList,TestList,D_features,X_features,Y_features):\n",
    "    NBModelsAUC=[]\n",
    "    NBTestPreds=[]\n",
    "    for i in range(0,len(TrainList)): \n",
    "        dft = pd.get_dummies(TrainList[i][D_features+X_features])\n",
    "        nb=MultinomialNB()\n",
    "        nb.fit(dft,TrainList[i][Y_features])\n",
    "        dft = pd.get_dummies(TestList[i][D_features+X_features])\n",
    "        proba=nb.predict_proba(dft)\n",
    "        ytrue=TestList[i][Y_features]\n",
    "        testauc=roc_auc_score(ytrue, proba[:, 1])\n",
    "        NBModelsAUC.append(testauc)\n",
    "        dft=TestList[i][D_features+X_features+Y_features]\n",
    "        dft['pred']=proba[:,1]\n",
    "        NBTestPreds.append(dft)\n",
    "    return NBModelsAUC,NBTestPreds\n",
    "\n",
    "\n",
    "def RunSVClassifier(TrainList,TestList,TrainNewList,TestNewList,D_features,X_features,Y_features):\n",
    "    SVModelsAUC=[]\n",
    "    SVTestPreds=[]\n",
    "    for i in range(0,len(TrainNewList)):\n",
    "        dft = pd.get_dummies(TrainNewList[i][D_features+X_features])\n",
    "        svc=SVC(probability=True, random_state=0, C=1.0)\n",
    "        svc.fit(dft,TrainNewList[i][Y_features])\n",
    "        dft = pd.get_dummies(TestNewList[i][D_features+X_features])\n",
    "        proba=svc.predict_proba(dft)\n",
    "        ytrue=TestList[i][Y_features]\n",
    "        testauc=roc_auc_score(ytrue, proba[:, 1])\n",
    "        SVModelsAUC.append(testauc)\n",
    "        dft=TestList[i][D_features+X_features+Y_features]\n",
    "        dft['pred']=proba[:,1]\n",
    "        SVTestPreds.append(dft)\n",
    "    return SVModelsAUC,SVTestPreds\n",
    "\n",
    "def RunSVWithoutDClassifier(TrainList,TestList,D_features,X_features,Y_features):\n",
    "    SVModelsAUC=[]\n",
    "    SVTestPreds=[]\n",
    "    for i in range(0,len(TrainList)): \n",
    "        dft = pd.get_dummies(TrainList[i][X_features])\n",
    "        svc = SVC(kernel='linear',probability=True)\n",
    "        svc.fit(dft,TrainList[i][Y_features])\n",
    "        dft = pd.get_dummies(TestList[i][X_features])\n",
    "        proba=svc.predict_proba(dft)\n",
    "        ytrue=TestList[i][Y_features]\n",
    "        testauc=roc_auc_score(ytrue, proba[:, 1])\n",
    "        SVModelsAUC.append(testauc)\n",
    "        dft=TestList[i][D_features+X_features+Y_features]\n",
    "        dft['pred']=proba[:,1]\n",
    "        SVTestPreds.append(dft)\n",
    "    return SVModelsAUC,SVTestPreds\n",
    "\n",
    "def RunPlainSVClassifier(TrainList,TestList,D_features,X_features,Y_features):\n",
    "    SVModelsAUC=[]\n",
    "    SVTestPreds=[]\n",
    "    for i in range(0,len(TrainList)): \n",
    "        dft = pd.get_dummies(TrainList[i][D_features+X_features])\n",
    "        svc = SVC(kernel='linear',probability=True)\n",
    "        svc.fit(dft,TrainList[i][Y_features])\n",
    "        dft = pd.get_dummies(TestList[i][D_features+X_features])\n",
    "        proba=svc.predict_proba(dft)\n",
    "        ytrue=TestList[i][Y_features]\n",
    "        testauc=roc_auc_score(ytrue, proba[:, 1])\n",
    "        SVModelsAUC.append(testauc)\n",
    "        dft=TestList[i][D_features+X_features+Y_features]\n",
    "        dft['pred']=proba[:,1]\n",
    "        SVTestPreds.append(dft)\n",
    "    return SVModelsAUC,SVTestPreds\n",
    "\n",
    "def ComputeDiscrimination(LRTestPreds,D_features):\n",
    "    test_disc=[]\n",
    "    for i in range(0,len(LRTestPreds)):\n",
    "        mean = LRTestPreds[i].groupby(D_features)['pred'].mean()\n",
    "        v = mean.values\n",
    "        v = v.reshape(len(v),1)\n",
    "        ratio_df = pd.DataFrame(v/v.transpose(),index=mean.index,columns=mean.index )\n",
    "        ratio_df_arr=np.asarray(np.abs(1-ratio_df))\n",
    "        maxdisc=np.amax(ratio_df_arr)\n",
    "        test_disc.append(maxdisc)   \n",
    "    return test_disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd3679e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#LRres=RunLRClassifier(TrainList,TestList,TrainNewList,TestNewList,D_features,X_features,Y_features)\n",
    "#LRres=RunPlainLRClassifier(TrainList,TestList,D_features,X_features,Y_features)\n",
    "LRres=RunLRWithoutDClassifier(TrainList,TestList,D_features,X_features,Y_features)\n",
    "LRDisc=ComputeDiscrimination(LRres[1],D_features)\n",
    "\n",
    "#RFres=RunRFClassifier(TrainList,TestList,TrainNewList,TestNewList,D_features,X_features,Y_features)\n",
    "#RFres=RunPlainRFClassifier(TrainList,TestList,D_features,X_features,Y_features)\n",
    "#RFres=RunRFWithoutDClassifier(TrainList,TestList,D_features,X_features,Y_features)\n",
    "#RFDisc=ComputeDiscrimination(RFres[1],D_features)\n",
    "\n",
    "#NBres=RunNBClassifier(TrainList,TestList,TrainNewList,TestNewList,D_features,X_features,Y_features)\n",
    "#NBres=RunPlainNBClassifier(TrainList,TestList,D_features,X_features,Y_features)\n",
    "#NBres=RunNBWithoutDClassifier(TrainList,TestList,D_features,X_features,Y_features)\n",
    "#NBDisc=ComputeDiscrimination(NBres[1],D_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0757edcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.stats import t\n",
    "LRAUC4=np.asarray(LRres[0])\n",
    "LR_mean4 = np.mean(LRAUC4)\n",
    "\n",
    "zemelauc=np.asarray([0.676842373423,0.693,0.687,0.693,0.699])\n",
    "#zemelauc=np.asarray([0.706,0.682,0.701,0.705,0.706])\n",
    "zemel_mean=np.mean(zemelauc)\n",
    "\n",
    "# standard deviation\n",
    "LR_std4 = np.std(LRAUC4)\n",
    "zemel_std=np.std(zemelauc)\n",
    "\n",
    "LRDisc4=np.asarray(LRDisc)\n",
    "LRdisc_mean4 = np.mean(LRDisc4)\n",
    "LRdisc_std4=np.std(LRDisc4)\n",
    "\n",
    "zemel_disc=np.asarray([0.0197,0.0122,0.0149,0.046])\n",
    "#zemel_disc=np.asarray([0.265,0.375,0.284,0.303,0.330])\n",
    "zemel_disc_mean=np.mean(zemel_disc)\n",
    "zemel_disc_std=np.std(zemel_disc)\n",
    "\n",
    "# standard error\n",
    "#RF_se3 = RF_std3 / np.sqrt(RFAUC3.size)\n",
    "\n",
    "#zemel_se=zemel_std/np.sqrt(zemelauc.size)\n",
    "\n",
    "#zemel_antidiscrim=0\n",
    "#zemelaccuracyvals=np.asarray([0.76,0.78])\n",
    "#zemel_mean=np.mean(zemelaccuracyvals)\n",
    "#zemel_std=np.std(zemelaccuracyvals)\n",
    "\n",
    "#dof = LRAUC5.size - 1         # degrees of freedom\n",
    "#dof=zemelauc.size-1\n",
    "alpha = 1.0 - 0.95\n",
    "#conf_interval = t.ppf(1-alpha/2., dof) * LR_std1*np.sqrt(1.+1./LRAUC1.size)\n",
    "#conf_interval = t.ppf(1-alpha/2., dof) * zemel_std*np.sqrt(1.+1./zemelauc.size)\n",
    "\n",
    "fig = plt.gca()\n",
    "font_options={'family' : 'sans-serif'}\n",
    "plt.rc('font', **font_options)\n",
    "\n",
    "# plt.errorbar(LRdisc_mean2, LR_mean2, xerr=LRdisc_std2, yerr=LR_std2, fmt='-o') #RF\n",
    "plt.errorbar(LRdisc_mean4, LR_mean4, xerr=LRdisc_std4, yerr=LR_std4, fmt='-o') # RF + Dropping D\n",
    "plt.errorbar(zemel_disc_mean, zemel_mean, xerr=zemel_disc_std, yerr=zemel_std, fmt='-o') # Zemel\n",
    "# plt.errorbar(LRdisc_mean1, LR_mean1, xerr=LRdisc_std1, yerr=LR_std1, fmt='-o') # RF + 0.05 (eps)\n",
    "# plt.errorbar(LRdisc_mean3, LR_mean3, xerr=LRdisc_std3, yerr=LR_std3, fmt='-o') # RF + 0.1 (eps)\n",
    "\n",
    "#fig.axes.get_xaxis().set_visible(False)\n",
    "fig.spines[\"top\"].set_visible(False)  \n",
    "fig.spines[\"right\"].set_visible(False)  \n",
    "plt.tick_params(axis=\"both\", which=\"both\", bottom=\"off\", top=\"off\",  \n",
    "                labelbottom=\"on\", left=\"on\", right=\"off\", labelleft=\"on\")  \n",
    "\n",
    "plt.legend(['LR','LR + Dropping D','LFR','LR + Our approach(.05)','LR + Our approach(.1)'], \n",
    "           loc='best',fancybox=True)\n",
    "\n",
    "plt.ylabel('AUC')\n",
    "plt.xlabel('Discrimination')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816d60ec",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "743a343a",
   "metadata": {},
   "outputs": [],
   "source": [
    "races = ['Caucasian','African-American']\n",
    "dataset_path = r'../data/compas-scores-two-years.csv'\n",
    "compas_raw = pd.read_csv(\n",
    "    dataset_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dc21f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "compas_dataset = compas_raw[compas_raw.race.isin(races)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7876b5",
   "metadata": {},
   "source": [
    "# Run Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04fd8187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(age                        25.000000\n",
       " juv_fel_count               0.000000\n",
       " juv_misd_count             -2.340451\n",
       " juv_other_count             1.000000\n",
       " priors_count              -15.010999\n",
       " age_cat_25 - 45             1.000000\n",
       " age_cat_Greater than 45     0.000000\n",
       " age_cat_Less than 25        0.000000\n",
       " c_charge_degree_F           0.000000\n",
       " c_charge_degree_M           1.000000\n",
       " Name: 0, dtype: float64,\n",
       " 1.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tempeh.configurations import datasets\n",
    "\n",
    "compas_dataset = datasets[\"compas\"]()\n",
    "X_train, X_test = compas_dataset.get_X(format=pd.DataFrame)\n",
    "y_train, y_test = compas_dataset.get_y(format=pd.Series)\n",
    "(\n",
    "    sensitive_features_train,\n",
    "    sensitive_features_test,\n",
    ") = compas_dataset.get_sensitive_features(\"race\", format=pd.Series)\n",
    "X_train.loc[0], y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c611cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>juv_misd_count</th>\n",
       "      <th>juv_other_count</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>age_cat_25 - 45</th>\n",
       "      <th>age_cat_Greater than 45</th>\n",
       "      <th>age_cat_Less than 25</th>\n",
       "      <th>c_charge_degree_F</th>\n",
       "      <th>c_charge_degree_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.340451</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-15.010999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.129788</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.994487</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.513697</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3531</th>\n",
       "      <td>33.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3532</th>\n",
       "      <td>22.249714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.000266</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3533</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3534</th>\n",
       "      <td>48.106561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3535</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3536 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age  juv_fel_count  juv_misd_count  juv_other_count  priors_count  \\\n",
       "0     25.000000            0.0       -2.340451              1.0    -15.010999   \n",
       "1     26.000000            0.0        0.000000              0.0      0.000000   \n",
       "2     21.000000            0.0        0.000000              0.0      0.000000   \n",
       "3     29.129788            0.0        0.000000              0.0      6.000000   \n",
       "4     40.994487            0.0        0.000000              0.0      7.513697   \n",
       "...         ...            ...             ...              ...           ...   \n",
       "3531  33.000000            0.0        0.000000              0.0      3.000000   \n",
       "3532  22.249714            0.0        0.000000              0.0     23.000266   \n",
       "3533  35.000000            0.0        0.000000              0.0      7.000000   \n",
       "3534  48.106561            0.0        0.000000              0.0      0.000000   \n",
       "3535  31.000000            0.0        0.000000              0.0      0.000000   \n",
       "\n",
       "      age_cat_25 - 45  age_cat_Greater than 45  age_cat_Less than 25  \\\n",
       "0                 1.0                      0.0                   0.0   \n",
       "1                 1.0                      0.0                   0.0   \n",
       "2                 0.0                      0.0                   1.0   \n",
       "3                 1.0                      0.0                   0.0   \n",
       "4                 1.0                      0.0                   0.0   \n",
       "...               ...                      ...                   ...   \n",
       "3531              1.0                      0.0                   0.0   \n",
       "3532              1.0                      0.0                   0.0   \n",
       "3533              1.0                      0.0                   0.0   \n",
       "3534              0.0                      1.0                   0.0   \n",
       "3535              1.0                      0.0                   0.0   \n",
       "\n",
       "      c_charge_degree_F  c_charge_degree_M  \n",
       "0                   0.0                1.0  \n",
       "1                   1.0                0.0  \n",
       "2                   1.0                0.0  \n",
       "3                   0.0                1.0  \n",
       "4                   1.0                0.0  \n",
       "...                 ...                ...  \n",
       "3531                1.0                0.0  \n",
       "3532                0.0                1.0  \n",
       "3533                1.0                0.0  \n",
       "3534                1.0                0.0  \n",
       "3535                1.0                0.0  \n",
       "\n",
       "[3536 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7747faf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
